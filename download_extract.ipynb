{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PG9Ou75f1rEk"
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sat Mar 15 10:46:13 2025\n",
    "\n",
    "@author: adamg\n",
    "\"\"\"\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "#pip install --user pdfplumber pandas pyzipper requests google-auth google-auth-oauthlib google-auth-httplib2 google-api-python-client\n",
    "\n",
    "\n",
    "import requests\n",
    "\n",
    "import pyzipper  # To handle password-protected ZIP files\n",
    "\n",
    "# Google Drive API dependencies\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "from googleapiclient.http import MediaIoBaseUpload\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 1Ô∏è‚É£ DOWNLOAD ZIP FILE FROM WEB URL\n",
    "# -----------------------------\n",
    "\n",
    "zip_path = \"/tmp/protected.zip\"  # üîπ Temporary storage path\n",
    "\n",
    "zip_url = os.getenv('ZIP_URL')\n",
    "zip_password = os.getenv('ZIP_PASSWORD')\n",
    "\n",
    "response = requests.get(zip_url)\n",
    "if response.status_code == 200:\n",
    "    with open(zip_path, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    print(f\"‚úÖ ZIP file downloaded successfully: {zip_path}\")\n",
    "else:\n",
    "    print(\"‚ùå Failed to download ZIP file\")\n",
    "    exit()\n",
    "\n",
    "# -----------------------------\n",
    "# 2Ô∏è‚É£ EXTRACT PDF FROM PASSWORD-PROTECTED ZIP\n",
    "# -----------------------------\n",
    "\n",
    "zip_password_bytes = zip_password.encode('utf-8')\n",
    "pdf_filename = \"BJ_SFIO_wycena.pdf\"  # üîπ Replace with the actual PDF file name inside ZIP\n",
    "pdf_path = f\"/tmp/{pdf_filename}\"  # üîπ Extracted PDF storage\n",
    "\n",
    "\n",
    "with pyzipper.AESZipFile(zip_path, 'r') as zf:\n",
    "    try:\n",
    "        zf.setpassword(zip_password_bytes)\n",
    "        zf.extract(pdf_filename, \"/tmp/\")  # Extract to home directory\n",
    "\n",
    "        print(f\"‚úÖ PDF extracted: {pdf_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error extracting PDF: {e}\")\n",
    "        exit()\n",
    "\n",
    "\n",
    "## -----------------------------\n",
    "# 3Ô∏è‚É£ EXTRACT TABLE FROM PDF\n",
    "# -----------------------------\n",
    "\n",
    "pdf_path = \"/tmp/BJ_SFIO_wycena.pdf\"\n",
    "\n",
    "\n",
    "# Convert all pages of the PDF to images\n",
    "images = convert_from_path(pdf_path)\n",
    "\n",
    "# Store extracted data from all pages\n",
    "all_table_data = []\n",
    "\n",
    "# Regex pattern for DD.MM.YYYY date format\n",
    "date_pattern = re.compile(r\"\\b\\d{2}\\.\\d{2}\\.\\d{4}\\b\")\n",
    "\n",
    "# Loop through each page\n",
    "for page_num, img in enumerate(images):\n",
    "    print(f\"Processing page {page_num + 1}/{len(images)}...\")\n",
    "\n",
    "    # Convert image to OpenCV format\n",
    "    img_cv = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Improve contrast using CLAHE (Adaptive Histogram Equalization)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    gray = clahe.apply(gray)\n",
    "\n",
    "    # Apply adaptive thresholding\n",
    "    binary = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                   cv2.THRESH_BINARY, 15, 10)\n",
    "\n",
    "    # Remove noise using morphological operations\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Extract text using OCR (use PSM 4 for single-column text)\n",
    "    custom_config = r'--oem 3 --psm 4'\n",
    "    extracted_text = pytesseract.image_to_string(binary, config=custom_config)\n",
    "\n",
    "    # Split text into lines\n",
    "    extracted_lines = extracted_text.strip().split(\"\\n\")\n",
    "\n",
    "    # Debug: Print extracted text from each page\n",
    "    print(f\"Extracted text from page {page_num + 1}:\")\n",
    "    print(\"\\n\".join(extracted_lines[:1]))  # Show first 1 lines for debugging\n",
    "\n",
    "    # Store extracted rows for this page\n",
    "    page_table_data = []\n",
    "\n",
    "    # Process each line to filter only valid rows\n",
    "    for line in extracted_lines:\n",
    "        row_data = line.strip().split()  # Split row into columns based on spaces\n",
    "\n",
    "        if row_data and date_pattern.match(row_data[0]):  # Check if first column is a date\n",
    "            page_table_data.append(row_data)\n",
    "\n",
    "    print(f\"Extracted {len(page_table_data)} valid rows from page {page_num + 1}\")\n",
    "\n",
    "    # Append current page's rows to the main table\n",
    "    all_table_data.extend(page_table_data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 4Ô∏è‚É£ UPLOAD CSV TO GOOGLE DRIVE\n",
    "# -----------------------------\n",
    "\n",
    "# Convert to DataFrame and save with semicolon separator\n",
    "\n",
    "# Assuming all_table_data is your data\n",
    "# Your CSV data processing\n",
    "df = pd.DataFrame(all_table_data)  # Assuming all_table_data is defined\n",
    "csv_data = df.to_csv(index=False, header=False, sep=\";\").encode('utf-8')\n",
    "\n",
    "\n",
    "creds = service_account.Credentials.from_service_account_file('/tmp/credentials.json', scopes=['https://www.googleapis.com/auth/drive'])\n",
    "\n",
    "drive_service = build('drive', 'v3', credentials=creds)\n",
    "\n",
    "# File details\n",
    "file_name = \"filtered_table.csv\"\n",
    "\n",
    "# Correctly get the folder ID (replace 'Dane' with the actual folder name)\n",
    "folder_name = 'Dane'\n",
    "query = f\"name='{folder_name}' and mimeType='application/vnd.google-apps.folder' and trashed=false\"\n",
    "results = drive_service.files().list(q=query, spaces='drive', fields='files(id)').execute()\n",
    "items = results.get('files', [])\n",
    "\n",
    "if items:\n",
    "    folder_id = items[0]['id']\n",
    "else:\n",
    "    print(f\"‚ùå Folder '{folder_name}' not found in Google Drive.\")\n",
    "    exit()\n",
    "\n",
    "# Now use the correct folder ID in the file search query\n",
    "query = f\"name='{file_name}' and '{folder_id}' in parents\"\n",
    "results = drive_service.files().list(q=query, spaces='drive', fields='files(id)').execute()\n",
    "items = results.get('files', [])\n",
    "\n",
    "if items:\n",
    "    file_id = items[0]['id']\n",
    "    # Update the existing file as a new version\n",
    "    # The MediaIoBaseUpload class needs to be called directly, not as an attribute of drive_service.\n",
    "    media = MediaIoBaseUpload(io.BytesIO(csv_data), mimetype='text/csv', resumable=True)\n",
    "    updated_file = drive_service.files().update(fileId=file_id, media_body=media).execute()\n",
    "    print(f\"File '{file_name}' updated as a new version. File ID: {file_id}\")\n",
    "else:\n",
    "    # If the file doesn't exist, create it\n",
    "    file_metadata = {\n",
    "        'name': file_name,\n",
    "        'parents': [folder_id] \n",
    "    }\n",
    "    # The MediaIoBaseUpload class needs to be called directly, not as an attribute of drive_service.\n",
    "    media = MediaIoBaseUpload(io.BytesIO(csv_data), mimetype='text/csv', resumable=True)\n",
    "    created_file = drive_service.files().create(body=file_metadata, media_body=media, fields='id').execute()\n",
    "    file_id = created_file.get('id')\n",
    "    print(f\"File '{file_name}' created. File ID: {file_id}\")\n",
    "\n",
    "print(f\"Filtering complete. Extracted data from {len(images)} pages saved in 'filtered_table.csv'.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOtJsjpz9d+lkYsYdbkIYT6",
   "mount_file_id": "1I09nMLOlgXNJeSrUOUcol9espXiFEJL2",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
